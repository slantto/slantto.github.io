# *_Particle Filters for Vision Navigation_*

## To run

This is all Python 2.7.  Don't try this with 3

To run this project, you will need some repositories from elsewhere.  These include:
* NavPy from github (git clone https://github.com/NavPy/NavPy.git)
* You need pandas and tables (with the Anaconda distribution already)
* pyPnp from the ANTcenter gitlab (git clone https://git.antcenter.net/vision/pyPNP.git)
* neogeo from the ANTcenter gitlab (git clone https://git.antcenter.net/vision/neogeo.git)
* navfeatdb from the ANTcenter gitlab (https://git.antcenter.net/vision/navfeatdb.git)
* neogeodb from the ANTcenter gitlab (git clone https://git.antcenter.net/vision/neogeodb.git)
* pyFLANN from Anaconda distribution (at least the conda-forge version)
* Some files from Don Venable, including:
    * dugway_ciortho.hdf
    * fc2_f5.hdf
    * ned_vel.npy
    * neogeo_obs_1e6.npy
    * neogeo_out.npy
    * neogeo_out_1e6.npy
    * pytables_db.hdf
    * t_loc.npy
    * the output frile from neobinPF
    * the egm-15.tif file
    * srtm files for region 1
    * the extracted features and their associated meta data from the flight imagery (will find a way to host this, or you could make your own)

may want to conside commenting out the particle distribution plotting portion, as this will slow down the program some, and eat up space.
    
* Some files that are generated by other code to record the data in the images.  These can be generated by other code (neobin), including:
    * pyFLANN (Conda?)
    * neogeodb (ANTcenter)
    * neogeo (ANTcenter)
    * pyPNP (ANTcenter)
    * bcolz (Anaconda)
    * blessings (Anaconda)
    * progressive (Anaconda)

Not needed right now, but to generate the data that is an input to this, will need to run neobinPF.py

## An easier way -- docker!
The easist way to get this code running is to use the "create_docker.tar" file that is in the git lfs.  To use it...
1. Untar create_docker.tar
2. `cd create_docker`
3. `docker build -t was_base:latest .` 
    * Note that this step can take a while, especially when it is building the conda libraries.  In about 30 minutes though, you should have an image (labeled was_base ... or you can chnage that) that works
4. To have ParticleFitler works, it assumes that you have a directory where you want things to be.  Mine has three sub-directories:
    * data_files  -- required for the current ParticleFilter.py to work
    * pfresults -- ParticleFilter will put stuff here
    * ParticleFilterVisNav -- this is where the code sits currently, but it doesn't have to.  It just makes it a lot easier so the next command is all you have to do
    * pyPNP -- there are a few data files that ParticleFilter.py asks for that it finds in pyPNP.  This seems like bad practice (the data files should all be outside of where the code lives, especially some sub-library we are calling), but it is what it is
5. Once that is there, run `docker run -i -t -v <your_directory_here>:/mounted was_base /bin/bash`
    * You may want to add a `--name` option in the option section so you can quit and come back to this container easier
    * There may be other options you want to use.  The important things are:
        1. `was_base` is the name of the image you created in 3
        2. Mount the directory discussed in 4 at `/mounted`
    * You could also run something else.  /bin/bash works well for me

You should be running the code now.  All the installation, etc. is taken care of.

TODO:  Get a full docker running that enables you to VNC into it, maybe use PyCharms on it, etc.  Right now, it is just a thin docker that runs the code.  No editing, no debugging, just running.  This may be needed to get the code running faster using pyqtgraph as well.


